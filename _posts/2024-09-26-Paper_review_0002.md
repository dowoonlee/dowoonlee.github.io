---
title: PR0002) Learning to Retrieve In-Context Examples for Large Language Models
tags: PaperReview LLM In-ContextLearning DenseRetreival KnowledgeDistillation Few-shotLearning
---
[Learning to Retrieve In-Context Examples for Large Language Models](https://arxiv.org/abs/2307.07164)

## 제목 : Learning to Retrieve In-Context Examples for Large Language Models

- 논문 정보
  - 저자 : Liang Wang, Nan Yang, Furu Wei
  - 출판정보 : EACL / 2024
- 연구 목적
  - LLM의 in-context learning 성능을 향상시키기 위해 고품질의 in-context 예제를 식별할 수 있는 dense retriever를 반복적으로 학습하는 새로운 프레임 워크를 제안
- 방법론
  - LLM feedback을 기반으로 후보 예제의 품질을 평가하는 reward model을 학습
  - reward model의 지식을 bi-encoder 기반 dense retriever에 distillation
  - 학습된 retriever로 새로운 후보 집합ㅇ르 검색하여 이 과정을 반복. 이 방법은 knowledge distillation을 통해 LLM의 미세한 순위 신호를 dense retriever에 전달
- 주요결과
  - ![figure_01](/assets/images/paper_review/pr0002_01.png "Figure. 1")
  - LLM의 in-context learning 능력을 향상시키는 새로운 방법을 제시
  - LLM-R은 다양한 NLP task에서 기존 방법들을 능가하는 성능을 보여줌
  - 특히 unseen task와 다양한 크기의 LLM에 대한 일반화 능력 입증
- 한계점
  - Closed-book QA나 common-sense reasoning 등의 task에서는 상대적으로 적은 개선만 있음
- 평가 및 결론
  - LLM-R은 in-context learning을 위한 고품질 예제 검새에 효과적인 방법을 제시함
- Keywords
  - In-Context Learning, Dense Retreival, Knowledge Distillation, Few-shot Learning
